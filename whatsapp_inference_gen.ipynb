{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re, string, datetime, emoji, math, time, json\n",
    "from collections import defaultdict\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.image as mpimg\n",
    "from typing import Sequence, Tuple\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from pilmoji import Pilmoji\n",
    "from markdown_pdf import MarkdownPdf, Section\n",
    "from google import genai\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Change these as needed:\n",
    "# All of these are required for the main statistical inference\n",
    "WHATSAPP_GROUP_NAME = \"<your group name>\"\n",
    "DATA_EXPORTED_BY = \"<your name>\"\n",
    "NAME_OF_WHATSAPP_FILE = '<your file name>.txt'\n",
    "STARTING_DAY_OF_SAMPLE = datetime.date(1999,12,31)  # year, month, date format\n",
    "ENDING_DAY_OF_SAMPLE = datetime.date(2004,1,31)     # year, month, date format\n",
    "DATA_CUTOFF_STR = \"31st Jan 2004 <Edit this to be your real date>\"\n",
    "\n",
    "# This is optional, only if you want to generate the individual text report\n",
    "GEMINI_API_KEY = ''\n",
    "# If you choose to generate this, be mindful of the fact that you will be providing your text chat data to \n",
    "# google gemini, and they may process your data for training purposes based on their privacy policy.\n",
    "# The first pdf will be processed entirely in your device.\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "TTF_FONTFILE_PATH = \"DejaVuSans.ttf\"\n",
    "PDF_EXPORT = PdfPages(f\"{WHATSAPP_GROUP_NAME}_Statistical Inferences.pdf\") \n",
    "\n",
    "with open(NAME_OF_WHATSAPP_FILE,'r', encoding=\"utf8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_first_of_month_xticks(plt, keys):\n",
    "    xticks_dates = {}\n",
    "    for i, item in enumerate(keys):\n",
    "        try: date = datetime.datetime.fromisoformat(item[:-5])\n",
    "        except ValueError: date = datetime.datetime.fromisoformat(item)\n",
    "        if date.day == 1:\n",
    "            xticks_dates[i] = date.strftime(\"%b\\n%Y\")\n",
    "    plt.xticks(list(xticks_dates.keys()),list(xticks_dates.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_per_date = defaultdict(int)\n",
    "msgs_per_person = defaultdict(int)\n",
    "total_characters_per_person = defaultdict(int)\n",
    "daily_msg_count_per_person = defaultdict(lambda: defaultdict(int))\n",
    "hourly = {str(i):0 for i in range(24)}\n",
    "words = defaultdict(int)\n",
    "emojis_per_person = defaultdict(int)\n",
    "emojis = defaultdict(int)\n",
    "media = defaultdict(int)\n",
    "deleted = defaultdict(int)\n",
    "edited = defaultdict(int)\n",
    "all_person_messages = defaultdict(list)\n",
    "\n",
    "\n",
    "working_text =  raw_text.replace('‎','').replace('[','よ').replace(']','々')\n",
    "working_text = re.sub(\"\\nよ(\\d)(\\d)/(\\d)(\\d)/(\\d)(\\d), \",r\"末よ\\1\\2/\\3\\4/\\5\\6, \", working_text)\n",
    "\n",
    "data = '\\n末'.join(working_text.split(\"末\"))\n",
    "with open('temp.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "for entry in working_text.split(\"末\"):\n",
    "    try:\n",
    "        dt, a = entry.split('々 ', 1)\n",
    "        person, msg = a.split(\": \", 1)\n",
    "    except ValueError:\n",
    "        continue # Only system messages\n",
    "\n",
    "    date_time_obj = datetime.datetime.strptime(dt, 'よ%d/%m/%y, %I:%M:%S\\u202f%p')\n",
    "    hour = str(date_time_obj.hour)\n",
    "    date_iso = date_time_obj.date().isoformat()\n",
    "    author=person.split()[0]\n",
    "    if len(author) == 1:\n",
    "        author = person.split()[1]\n",
    "\n",
    "    if msg in ('video omitted', 'image omitted'):\n",
    "        media[author] += 1\n",
    "        continue\n",
    "    if msg.strip() in (\"This message was deleted.\", \"You deleted this message.\"):\n",
    "        deleted[author] += 1\n",
    "        continue\n",
    "    if msg.endswith(\"<This message was edited>\"):\n",
    "        edited[author] += 1\n",
    "        msg = msg.replace(\"<This message was edited>\",\"\")\n",
    "\n",
    "    \n",
    "    msgs_per_date[date_iso] += 1\n",
    "    msgs_per_person[author] += 1\n",
    "    total_characters_per_person[author] += len(msg)\n",
    "    daily_msg_count_per_person[author][date_iso] += 1\n",
    "    hourly[hour] += 1\n",
    "    all_person_messages[author].append(msg)\n",
    "    for raw in msg.split():\n",
    "        word = raw.strip(string.punctuation).lower()\n",
    "        if not word:\n",
    "            continue\n",
    "        words[word] += 1\n",
    "        emojis_per_person[author] += len(emoji.emoji_list(raw))\n",
    "    \n",
    "\n",
    "for entry in emoji.emoji_list(raw_text):\n",
    "    emojis[entry['emoji']] += 1\n",
    "\n",
    "# Adding empty dates\n",
    "def add_empty_dates(dict):\n",
    "    new = {}\n",
    "    current, last = STARTING_DAY_OF_SAMPLE, ENDING_DAY_OF_SAMPLE\n",
    "    while current <= last:\n",
    "        new[current.isoformat()] = dict[current.isoformat()] # Works because dict is a defaultdict\n",
    "        current += datetime.timedelta(days=1)\n",
    "    return new\n",
    "\n",
    "msgs_per_date = add_empty_dates(msgs_per_date)\n",
    "for person in daily_msg_count_per_person:\n",
    "    daily_msg_count_per_person[person] = add_empty_dates(daily_msg_count_per_person[person])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_black_png_with_centered_text_lines(\n",
    "        lines: Sequence[Tuple[str, int]],\n",
    "        filename: str = \"text_page.png\",\n",
    "        *,\n",
    "        width: int        = 3500,     # px\n",
    "        height: int | None = 2000,     # px; auto-size if None\n",
    "        line_spacing: float = 1.25,   # 1.0 = tight, >1 = looser\n",
    "        padding: int       = 80       # px margin top/bottom & left/right\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Render multiple lines of text (each with its own font size) into\n",
    "    a black PNG and return the saved path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lines : sequence of (text, font_size)\n",
    "        e.g. [(\"Title\", 60), (\"subtitle\", 40), (\"small note\", 24)]\n",
    "    filename : output file name\n",
    "    width / height : canvas size; if height is None it's auto-sized\n",
    "    font_path : TrueType/OTF font file; falls back to DejaVuSans or PIL default\n",
    "    line_spacing : inter-line multiplier applied to each line’s font metrics\n",
    "    padding : space between text block and image edge\n",
    "    \"\"\"\n",
    "\n",
    "    # ── 2. measure every line ──────────────────────────────────────────────\n",
    "    dummy = Image.new(\"RGB\", (1, 1))\n",
    "    draw_dummy = ImageDraw.Draw(dummy)\n",
    "\n",
    "    line_metrics = []  # (text, font, width_px, height_px)\n",
    "    max_line_px = width - 2 * padding\n",
    "\n",
    "    for txt, sz in lines:\n",
    "        font = ImageFont.truetype(TTF_FONTFILE_PATH, sz)\n",
    "        w = draw_dummy.textlength(txt, font=font)\n",
    "        if w > max_line_px:\n",
    "            raise ValueError(\n",
    "                f'\"{txt}\" (size {sz}) is wider than the allowed {max_line_px}px. '\n",
    "                \"Either provide a larger `width`, reduce `padding`, \"\n",
    "                \"or use shorter text.\"\n",
    "            )\n",
    "        ascent, descent = font.getmetrics()\n",
    "        h = int((ascent + descent) * line_spacing)\n",
    "        line_metrics.append((txt, font, w, h))\n",
    "\n",
    "    # ── 3. canvas height & creation ────────────────────────────────────────\n",
    "    text_block_h = sum(h for *_, h in line_metrics)\n",
    "    if height is None:\n",
    "        height = text_block_h + 2 * padding\n",
    "\n",
    "    img = Image.new(\"RGB\", (width, height), color=\"black\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # ── 4. render lines centred ────────────────────────────────────────────\n",
    "    y = (height - text_block_h) // 2\n",
    "    for txt, font, w, h in line_metrics:\n",
    "        x = (width - w) // 2\n",
    "        draw.text((x, y), txt, font=font, fill=\"white\")\n",
    "        y += h\n",
    "\n",
    "    img.save(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "cover_png = make_black_png_with_centered_text_lines([\n",
    "    (\"Statistical Inferences\", 120),\n",
    "    (f'based on \"{WHATSAPP_GROUP_NAME}\" chat messages', 90),\n",
    "    (\"\", 120),\n",
    "    (f\"Data Cut-off: {DATA_CUTOFF_STR}\", 90),\n",
    "    (\"\", 120),\n",
    "    (f\"Data Exported by: {DATA_EXPORTED_BY}\", 60),\n",
    "    (\"\", 120),\n",
    "    (\"Prepared by: Madhav AK | DA24B\", 60)\n",
    "], filename=f\"{WHATSAPP_GROUP_NAME}_cover.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_png_page(path, dpi=300):\n",
    "    \"\"\"\n",
    "    Reads a PNG (or any image Matplotlib supports) and writes it\n",
    "    as a full-page into an open PdfPages handle.\n",
    "    \"\"\"\n",
    "    img = mpimg.imread(path)\n",
    "\n",
    "    # Size the figure so the image is 1-for-1 at the chosen DPI\n",
    "    h_px, w_px = img.shape[:2]\n",
    "    fig = plt.figure(figsize=(w_px / dpi, h_px / dpi), dpi=dpi)\n",
    "\n",
    "    ax = fig.add_axes([0, 0, 1, 1])   # edge-to-edge\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(img)\n",
    "\n",
    "    PDF_EXPORT.savefig(fig)   # append to PDF\n",
    "    plt.close(fig)     # keep memory tidy\n",
    "\n",
    "add_png_page(cover_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_plot(title, x, y, color, special_month_xticks=True, rotation=0):\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize =(16, 8))\n",
    "    plt.bar(x,y, color=color)\n",
    "    if special_month_xticks:\n",
    "        set_first_of_month_xticks(plt, x)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xticks(rotation=rotation)\n",
    "    PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "def horizontal_tall_standard_plot(title, x, y, color, special_month_xticks=True, rotation=0):\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize =(8, 13))\n",
    "    plt.barh(list(reversed(x)), list(reversed(y)), color=color)\n",
    "    if special_month_xticks:\n",
    "        set_first_of_month_xticks(plt, x)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.yticks(rotation=rotation)\n",
    "    PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_plot(\"Messages Per Day\", msgs_per_date.keys(), msgs_per_date.values(), (1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly={}\n",
    "for date in msgs_per_date:\n",
    "    d = datetime.date.fromisoformat(date)\n",
    "    month = d.strftime('%b\\n%Y')\n",
    "    try: monthly[month] += msgs_per_date[date]\n",
    "    except KeyError: monthly[month] = msgs_per_date[date]\n",
    "standard_plot(\"Messages Per Month\", monthly.keys(), monthly.values(),(1,0,0),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_plot(\"Messages Per Hour\", [f\"{item}-{int(item)+1}\" for item in hourly.keys()], hourly.values(), (0,0,1), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Total Messages Sent\"\n",
    "sorted_tuples = sorted(msgs_per_person.items(), key= lambda item: item[1], reverse=True)\n",
    "fig = plt.figure(figsize =(10, 10))\n",
    "plt.pie(\n",
    "    x = [item[1] for item in sorted_tuples], \n",
    "    labels = [f\"{item[0]} | {(item[1])}\" for item in sorted_tuples],\n",
    "    explode = [[0.1,0][i%2] for i in range(len(msgs_per_person))]\n",
    "    )\n",
    "plt.title(title, fontsize=16)\n",
    "PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_msg_length = {}\n",
    "for person in msgs_per_person:\n",
    "    average_msg_length[person] = total_characters_per_person[person] / msgs_per_person[person]\n",
    "sorted_dict = {k:v for k,v in sorted(average_msg_length.items(), key= lambda item: item[1], reverse=True)[:20]}\n",
    "standard_plot(\"Average message length\", sorted_dict.keys(), sorted_dict.values(), (0,1,1), False, rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Number of Media Attachments\"\n",
    "sorted_tuples = sorted(media.items(), key= lambda item: item[1], reverse=True)\n",
    "fig = plt.figure(figsize =(10, 10))\n",
    "plt.pie(\n",
    "    x = [item[1] for item in sorted_tuples], \n",
    "    labels = [f\"{item[0]} | {(item[1])}\" for item in sorted_tuples],\n",
    "    explode = [[0.1,0][i%2] for i in range(len(media))]\n",
    "    )\n",
    "plt.title(title, fontsize=16)\n",
    "PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Number of deleted messages\"\n",
    "sorted_tuples = sorted(deleted.items(), key= lambda item: item[1], reverse=True)\n",
    "fig = plt.figure(figsize =(10, 10))\n",
    "plt.pie(\n",
    "    x = [item[1] for item in sorted_tuples], \n",
    "    labels = [f\"{item[0]} | {(item[1])}\" for item in sorted_tuples],\n",
    "    explode = [[0.1,0][i%2] for i in range(len(deleted))]\n",
    "    )\n",
    "plt.title(title, fontsize=16)\n",
    "PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editer_ratio = {person:deleted[person]*100 / msgs_per_person[person] for person in deleted} \n",
    "sorted_dict = {k:v for k,v in sorted(editer_ratio.items(), key= lambda item: item[1], reverse=True)[:20]}\n",
    "horizontal_tall_standard_plot(\"Percentage of Msgs deleted\", sorted_dict.keys(), sorted_dict.values(), (1,1,0), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Number of edited messages\"\n",
    "sorted_tuples = sorted(edited.items(), key= lambda item: item[1], reverse=True)\n",
    "fig = plt.figure(figsize =(10, 10))\n",
    "plt.pie(\n",
    "    x = [item[1] for item in sorted_tuples], \n",
    "    labels = [f\"{item[0]} | {(item[1])}\" for item in sorted_tuples],\n",
    "    explode = [[0.1,0][i%2] for i in range(len(edited))]\n",
    "    )\n",
    "plt.title(title, fontsize=16)\n",
    "PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editer_ratio = {person:edited[person]*100 / msgs_per_person[person] for person in edited} \n",
    "sorted_dict = {k:v for k,v in sorted(editer_ratio.items(), key= lambda item: item[1], reverse=True)[:20]}\n",
    "horizontal_tall_standard_plot(\"Percentage of Msgs edited\", sorted_dict.keys(), sorted_dict.values(), (1,1,0), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Number of Emojis Sent\"\n",
    "sorted_tuples = sorted(emojis_per_person.items(), key= lambda item: item[1], reverse=True)\n",
    "fig = plt.figure(figsize =(10, 10))\n",
    "plt.pie(\n",
    "    x = [item[1] for item in sorted_tuples], \n",
    "    labels = [f\"{item[0]} | {(item[1])}\" for item in sorted_tuples],\n",
    "    explode = [[0.1,0][i%2] for i in range(len(emojis_per_person))]\n",
    "    )\n",
    "plt.title(title, fontsize=16)\n",
    "PDF_EXPORT.savefig(fig, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_emojis = sorted(emojis.items(), key=lambda tup: tup[1], reverse=True)[:15]\n",
    "print(\"Most Used Emojis:\")\n",
    "for item in ranked_emojis:\n",
    "    print(item[0], '' ,item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emojis_to_png(emojis,\n",
    "                  outfile,\n",
    "                  *,\n",
    "                  top_n=15,\n",
    "                  font_size=72,\n",
    "                  font_path=None,\n",
    "                  padding=40,\n",
    "                  line_spacing=1.15):\n",
    "\n",
    "    # ✦ choose a font that has the ASCII digits we’ll print\n",
    "    font_path = TTF_FONTFILE_PATH\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # ── layout pass ───────────────────────────────────────────────────────\n",
    "    ranked  = sorted(emojis.items(), key=lambda t: t[1], reverse=True)[:top_n]\n",
    "    line_h  = int(font_size * line_spacing)           # already an int\n",
    "\n",
    "    dummy   = Image.new(\"RGB\", (1, 1))\n",
    "    draw    = ImageDraw.Draw(dummy)\n",
    "    max_w   = max(draw.textlength(f\"{g}  {c}\", font=font) for g, c in ranked)\n",
    "\n",
    "    w = int(math.ceil(max_w + padding * 2))           # ← cast to int\n",
    "    h = int(line_h * len(ranked) + padding * 2)       # already int-ish, but be safe\n",
    "\n",
    "    # ── render pass ───────────────────────────────────────────────────────\n",
    "    im = Image.new(\"RGBA\", (w, h), \"black\")\n",
    "    with Pilmoji(im) as pilmoji:\n",
    "        y = padding\n",
    "        for glyph, count in ranked:\n",
    "            pilmoji.text((padding, y),\n",
    "                         f\"{glyph}  {count}\",\n",
    "                         font=font,\n",
    "                         fill=\"white\")\n",
    "            y += line_h\n",
    "\n",
    "    im.save(outfile)\n",
    "    print(f\"✅  Saved {outfile}\")\n",
    "\n",
    "\n",
    "emoji_outfile=f\"{WHATSAPP_GROUP_NAME}_emoji_stats.png\"\n",
    "emojis_to_png({k: v for k, v in ranked_emojis}, outfile=emoji_outfile)\n",
    "add_png_page(emoji_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_EXPORT.close()\n",
    "print(\"Saved statistical inferences pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GEMINI_API_KEY:\n",
    "\traise ValueError (\"You didnt put a gemini api key\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "llm_output_dict = {}\n",
    "\n",
    "for person, all_msgs in all_person_messages.items():\n",
    "\tall_text = '\\n'.join(all_msgs)\n",
    "\tquery = f\"Here are all the messages sent by a particular person:\\n{all_text}\\n\\nBased on all this data, point out any strengths, and any flaws/vulneribilities of this person. Note this is an informat text chat, so don't mention anything regarding clarity of comminication, or informal language.\"\n",
    "\tllm_response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=query).text\n",
    "\tllm_output_dict[person] = llm_response\n",
    "\tprint(person, end = ' ')\n",
    "\ttime.sleep(2)\n",
    "\n",
    "with open(f\"{WHATSAPP_GROUP_NAME} person best and worst.json\", 'w') as f:\n",
    "\tjson.dump(llm_output_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WHATSAPP_GROUP_NAME} person best and worst.json\", 'r') as f:\n",
    "\tllm_output_dict = json.load(f)\n",
    "order_of_people = sorted(msgs_per_person.items(), key= lambda item: item[1], reverse=True)\n",
    "single_text = \"\"\n",
    "for tup in order_of_people:\n",
    "\tperson = tup[0]\n",
    "\tsummary = llm_output_dict[person]\n",
    "\tsingle_text = f\"{single_text}# {person}:\\n{summary}\\n\\n\\n\"\n",
    "with open(f\"{WHATSAPP_GROUP_NAME} person best and worst.md\", 'w', encoding=\"utf-8\") as f:\n",
    "\tf.write(single_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WHATSAPP_GROUP_NAME} person best and worst.md\" , 'r', encoding=\"utf-8\") as f:\n",
    "    markdown_content = f.read()\n",
    "\n",
    "pdf = MarkdownPdf()\n",
    "pdf.meta[\"title\"] = 'Title'\n",
    "pdf.add_section(Section(markdown_content, toc=False))\n",
    "pdf.save(f'{WHATSAPP_GROUP_NAME} Individual Strength-Weaknesses-Flaws.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
